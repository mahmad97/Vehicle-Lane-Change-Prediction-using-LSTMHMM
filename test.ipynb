{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be7415f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import smtplib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import models\n",
    "\n",
    "from email.message import EmailMessage\n",
    "from matplotlib.pylab import plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb03b735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Quadro RTX 6000\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3, 1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3, 1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b804118a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/home/mma6789/Stuff/Studies/sem3/ms_project' #@param {type: 'string'}\n",
    "\n",
    "dataset = 'US-101' #@param ['I-80', 'US-101']\n",
    "t_o = 5000 #@param [3000, 4000, 5000] -> observation horizon\n",
    "t_p = 3500 #@param [1500, 2000, 2500] -> prediction horizon\n",
    "\n",
    "method = 'LSTMHMM' #@param ['LSTM', 'HMM', 'LSTMHMM']\n",
    "\n",
    "timesteps = t_o // 100\n",
    "variables = 5\n",
    "learning_rate = 0.0002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9f795da",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load data splits\n",
    "test = np.load(f'{base_dir}/data/processed/{dataset}/{t_o}_{t_p}_test.npy')\n",
    "\n",
    "test_X, test_y = np.split(test, [-3], axis=1)\n",
    "\n",
    "temp = np.empty((len(test_X), timesteps, variables))\n",
    "for i in range(len(test_X)):\n",
    "    temp[i] = np.array(np.split(test_X[i], timesteps))\n",
    "test_X = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8f5119a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = torch.tensor(test_X).float()\n",
    "test_y = torch.tensor(test_y).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7bf3b46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.y[i]\n",
    "\n",
    "test_dataset = LSTMDataset(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1fa342b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 192\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff5cd190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch():\n",
    "    model.train(False)\n",
    "    running_loss = 0.0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    for batch_index, batch in enumerate(tqdm(test_loader, desc=f'Test')):\n",
    "        x_batch, y_batch = batch[0].to(device), batch[1].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(x_batch)\n",
    "            \n",
    "        y_true += torch.argmax(y_batch, dim=1).flatten().tolist()\n",
    "        y_pred += torch.argmax(output, dim=1).cpu().detach().numpy().tolist()\n",
    "            \n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    matrix = confusion_matrix(y_true, y_pred)\n",
    "    class_acc = matrix.diagonal() / matrix.sum(axis=1)\n",
    "    \n",
    "    test_acc.append(acc)\n",
    "    test_f1.append(f1)\n",
    "    test_class_acc.append(class_acc)\n",
    "    \n",
    "    print('Test results:')\n",
    "    print(f'Acc: {acc}')\n",
    "    print(f'F1: {f1}')\n",
    "    print(f'Class Acc: {class_acc}')\n",
    "    print('***************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc1976c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Three_LSTMHMM(\n",
       "  (lcl_model): LSTMHMM(\n",
       "    (transition_model): TransitionModel()\n",
       "    (emission_model): LSTMEmissionModel(\n",
       "      (lstm): LSTM(5, 150, batch_first=True)\n",
       "      (linear): Linear(in_features=150, out_features=30, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (lk_model): LSTMHMM(\n",
       "    (transition_model): TransitionModel()\n",
       "    (emission_model): LSTMEmissionModel(\n",
       "      (lstm): LSTM(5, 150, batch_first=True)\n",
       "      (linear): Linear(in_features=150, out_features=30, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (lcr_model): LSTMHMM(\n",
       "    (transition_model): TransitionModel()\n",
       "    (emission_model): LSTMEmissionModel(\n",
       "      (lstm): LSTM(5, 150, batch_first=True)\n",
       "      (linear): Linear(in_features=150, out_features=30, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load model from file\n",
    "model = torch.load(f'{base_dir}/models/{method}/{dataset}/model_{t_o}_{t_p}_{learning_rate}.pt')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d147e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "006e115f31264b378aaa00ca0d70616b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test:   0%|          | 0/1949 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results:\n",
      "Acc: 0.9784757725497951\n",
      "F1: 0.980436711033607\n",
      "Class Acc: [0.96936456 0.97874857 0.97747587]\n",
      "***************************************************\n"
     ]
    }
   ],
   "source": [
    "## Test model\n",
    "test_acc = []\n",
    "test_f1 = []\n",
    "test_class_acc = []\n",
    "\n",
    "test_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c2cd7d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write metrics to file\n",
    "metrics = pd.DataFrame(data={\n",
    "    'test_acc': test_acc, 'test_f1': test_f1, 'test_class_acc': test_class_acc,\n",
    "})\n",
    "\n",
    "metrics.to_json(f'{base_dir}/metrics/{method}/{dataset}/testing_{t_o}_{t_p}_{learning_rate}.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ab7d1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
